"""
ä¼šè©±å±¥æ­´ã‹ã‚‰éèªçŸ¥èƒ½åŠ›ã‚’åˆ†æã™ã‚‹MLãƒ¢ãƒ‡ãƒ«
"""

import os
import re
from dataclasses import dataclass
from typing import Dict, List, Optional

import joblib
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler


@dataclass
class NonCognitiveSkills:
    """éèªçŸ¥èƒ½åŠ›ã‚¹ã‚³ã‚¢"""

    grit: float  # ã‚„ã‚ŠæŠœãåŠ› (0.0-5.0)
    collaboration: float  # å”èª¿æ€§ (0.0-5.0)
    self_regulation: float  # è‡ªå·±åˆ¶å¾¡ (0.0-5.0)
    emotional_intelligence: float  # æ„Ÿæƒ…çŸ¥èƒ½ (0.0-5.0)
    confidence: float = 0.0  # è‡ªä¿¡ (0.0-5.0)


@dataclass
class ConversationMetrics:
    """ä¼šè©±ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    message_count: int
    avg_message_length: float
    question_count: int
    positive_words_count: int
    negative_words_count: int
    learning_keywords_count: int
    help_seeking_count: int
    completion_rate: float  # å•é¡Œè§£æ±ºå®Œäº†ç‡


class ConversationAnalyzer:
    """ä¼šè©±å±¥æ­´ã‹ã‚‰éèªçŸ¥èƒ½åŠ›ã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.grit_model = None
        self.collaboration_model = None
        self.self_regulation_model = None
        self.emotional_intelligence_model = None
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words="english")
        self.scaler = StandardScaler()
        self._load_models()

    def _load_models(self):
        """äº‹å‰è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        models_dir = os.path.join(os.path.dirname(__file__), "trained_models")

        if os.path.exists(models_dir):
            try:
                self.grit_model = joblib.load(
                    os.path.join(models_dir, "grit_model.pkl")
                )
                self.collaboration_model = joblib.load(
                    os.path.join(models_dir, "collaboration_model.pkl")
                )
                self.self_regulation_model = joblib.load(
                    os.path.join(models_dir, "self_regulation_model.pkl")
                )
                self.emotional_intelligence_model = joblib.load(
                    os.path.join(models_dir, "emotional_intelligence_model.pkl")
                )
                self.vectorizer = joblib.load(
                    os.path.join(models_dir, "vectorizer.pkl")
                )
                self.scaler = joblib.load(os.path.join(models_dir, "scaler.pkl"))
            except FileNotFoundError:
                print(
                    "äº‹å‰è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
                )
                self._create_default_models()
        else:
            self._create_default_models()

    def _create_default_models(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        self.grit_model = self._create_rule_based_model()
        self.collaboration_model = self._create_rule_based_model()
        self.self_regulation_model = self._create_rule_based_model()
        self.emotional_intelligence_model = self._create_rule_based_model()

    def _create_rule_based_model(self):
        """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«"""

        class RuleBasedModel:
            def predict(self, X):
                return np.random.uniform(1.0, 4.0, len(X))

        return RuleBasedModel()

    def analyze_conversation(self, messages: List[Dict]) -> NonCognitiveSkills:
        """ä¼šè©±å±¥æ­´ã‚’åˆ†æã—ã¦éèªçŸ¥èƒ½åŠ›ã‚¹ã‚³ã‚¢ã‚’ç®—å‡º"""

        # ä¼šè©±ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
        metrics = self._calculate_conversation_metrics(messages)

        # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        conversation_text = self._extract_conversation_text(messages)

        # ç‰¹å¾´é‡ã‚’æŠ½å‡º
        features = self._extract_features(conversation_text, metrics)

        # å„éèªçŸ¥èƒ½åŠ›ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬
        grit_score = self._predict_grit(features)
        collaboration_score = self._predict_collaboration(features)
        self_regulation_score = self._predict_self_regulation(features)
        emotional_intelligence_score = self._predict_emotional_intelligence(features)
        confidence_score = self._predict_confidence(features)

        return NonCognitiveSkills(
            grit=grit_score,
            collaboration=collaboration_score,
            self_regulation=self_regulation_score,
            emotional_intelligence=emotional_intelligence_score,
            confidence=confidence_score,
        )

    def _calculate_conversation_metrics(
        self, messages: List[Dict]
    ) -> ConversationMetrics:
        """ä¼šè©±ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—"""
        user_messages = [msg for msg in messages if msg.get("role") == "user"]

        total_messages = len(user_messages)
        total_length = sum(len(msg.get("content", "")) for msg in user_messages)
        avg_length = total_length / max(total_messages, 1)

        # è³ªå•ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        question_count = sum(
            1
            for msg in user_messages
            if "?" in msg.get("content", "")
            or "ã§ã™ã‹" in msg.get("content", "")
            or "ã§ã—ã‚‡ã†ã‹" in msg.get("content", "")
        )

        # ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        positive_words = [
            "é ‘å¼µã‚‹",
            "åŠªåŠ›",
            "ç¶šã‘ã‚‹",
            "æŒ‘æˆ¦",
            "å­¦ã¶",
            "ç†è§£",
            "ã§ããŸ",
            "æˆåŠŸ",
            "å¬‰ã—ã„",
            "æ¥½ã—ã„",
        ]
        negative_words = [
            "é›£ã—ã„",
            "ã‚ã‹ã‚‰ãªã„",
            "ã§ããªã„",
            "å›°ã£ãŸ",
            "ç–²ã‚ŒãŸ",
            "å«Œã„",
            "è‹¦æ‰‹",
            "å¤±æ•—",
        ]

        all_text = " ".join(msg.get("content", "") for msg in user_messages)
        positive_count = sum(all_text.count(word) for word in positive_words)
        negative_count = sum(all_text.count(word) for word in negative_words)

        # å­¦ç¿’é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        learning_keywords = [
            "å‹‰å¼·",
            "å­¦ç¿’",
            "å•é¡Œ",
            "èª²é¡Œ",
            "å®¿é¡Œ",
            "æˆæ¥­",
            "æ•™ç§‘æ›¸",
            "ãƒ†ã‚¹ãƒˆ",
            "è©¦é¨“",
        ]
        learning_keywords_count = sum(
            all_text.count(word) for word in learning_keywords
        )

        # ãƒ˜ãƒ«ãƒ—ã‚·ãƒ¼ã‚­ãƒ³ã‚°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        help_words = [
            "æ•™ãˆã¦",
            "åŠ©ã‘ã¦",
            "æ‰‹ä¼ã£ã¦",
            "ã‚ã‹ã‚‰ãªã„",
            "å›°ã£ã¦ã„ã‚‹",
            "ã©ã†ã™ã‚Œã°",
        ]
        help_seeking_count = sum(all_text.count(word) for word in help_words)

        # å®Œäº†ç‡ï¼ˆç°¡æ˜“ç‰ˆï¼šè³ªå•ã«å¯¾ã™ã‚‹è¿”ç­”ã®æœ‰ç„¡ï¼‰
        completion_rate = min(
            1.0, total_messages / max(1, len(messages) - total_messages)
        )

        return ConversationMetrics(
            message_count=total_messages,
            avg_message_length=avg_length,
            question_count=question_count,
            positive_words_count=positive_count,
            negative_words_count=negative_count,
            learning_keywords_count=learning_keywords_count,
            help_seeking_count=help_seeking_count,
            completion_rate=completion_rate,
        )

    def _extract_conversation_text(self, messages: List[Dict]) -> str:
        """ä¼šè©±ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        user_messages = [msg for msg in messages if msg.get("role") == "user"]
        return " ".join(msg.get("content", "") for msg in user_messages)

    def _extract_features(
        self, conversation_text: str, metrics: ConversationMetrics
    ) -> np.ndarray:
        """ç‰¹å¾´é‡ã‚’æŠ½å‡º"""
        features = [
            metrics.message_count,
            metrics.avg_message_length,
            metrics.question_count,
            metrics.positive_words_count,
            metrics.negative_words_count,
            metrics.learning_keywords_count,
            metrics.help_seeking_count,
            metrics.completion_rate,
            len(conversation_text.split()),
            len(re.findall(r"[!ï¼]", conversation_text)),  # æ„Ÿå˜†ç¬¦ã®æ•°
            len(re.findall(r"[?ï¼Ÿ]", conversation_text)),  # ç–‘å•ç¬¦ã®æ•°
        ]

        return np.array(features).reshape(1, -1)

    def _predict_grit(self, features: np.ndarray) -> float:
        """ã‚°ãƒªãƒƒãƒˆï¼ˆã‚„ã‚ŠæŠœãåŠ›ï¼‰ã‚’äºˆæ¸¬"""
        if self.grit_model:
            score = self.grit_model.predict(features)[0]
        else:
            # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“äºˆæ¸¬
            score = min(
                5.0, max(1.0, 2.0 + features[0][2] * 0.1 + features[0][3] * 0.2)
            )
        return round(score, 2)

    def _predict_collaboration(self, features: np.ndarray) -> float:
        """å”èª¿æ€§ã‚’äºˆæ¸¬"""
        if self.collaboration_model:
            score = self.collaboration_model.predict(features)[0]
        else:
            # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“äºˆæ¸¬
            score = min(
                5.0, max(1.0, 2.0 + features[0][6] * 0.3 + features[0][9] * 0.1)
            )
        return round(score, 2)

    def _predict_self_regulation(self, features: np.ndarray) -> float:
        """è‡ªå·±åˆ¶å¾¡ã‚’äºˆæ¸¬"""
        if self.self_regulation_model:
            score = self.self_regulation_model.predict(features)[0]
        else:
            # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“äºˆæ¸¬
            score = min(
                5.0, max(1.0, 2.0 + features[0][1] * 0.1 + features[0][7] * 0.4)
            )
        return round(score, 2)

    def _predict_emotional_intelligence(self, features: np.ndarray) -> float:
        """æ„Ÿæƒ…çŸ¥èƒ½ã‚’äºˆæ¸¬"""
        if self.emotional_intelligence_model:
            score = self.emotional_intelligence_model.predict(features)[0]
        else:
            # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“äºˆæ¸¬
            score = min(
                5.0, max(1.0, 2.0 + features[0][3] * 0.2 - features[0][4] * 0.1)
            )
        return round(score, 2)

    def _predict_confidence(self, features: np.ndarray) -> float:
        """è‡ªä¿¡ã‚’äºˆæ¸¬"""
        # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“äºˆæ¸¬
        score = min(5.0, max(1.0, 2.0 + features[0][3] * 0.2 + features[0][7] * 0.3))
        return round(score, 2)

    def generate_feedback(
        self,
        skills: NonCognitiveSkills,
        previous_skills: Optional[NonCognitiveSkills] = None,
    ) -> str:
        """éèªçŸ¥èƒ½åŠ›ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ"""

        feedback_parts = []

        # å„ã‚¹ã‚­ãƒ«ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        if skills.grit >= 4.0:
            feedback_parts.append(
                "ğŸŒŸ ç´ æ™´ã‚‰ã—ã„ã‚„ã‚ŠæŠœãåŠ›ã‚’æŒã£ã¦ã„ã¾ã™ï¼å›°é›£ãªèª²é¡Œã«ã‚‚è«¦ã‚ãšã«å–ã‚Šçµ„ã‚€å§¿å‹¢ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚"
            )
        elif skills.grit >= 3.0:
            feedback_parts.append(
                "ğŸ‘ ã‚„ã‚ŠæŠœãåŠ›ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ã€‚ç›®æ¨™ã‚’è¨­å®šã—ã¦ç¶™ç¶šçš„ã«å–ã‚Šçµ„ã‚“ã§ã¿ã¾ã—ã‚‡ã†ã€‚"
            )
        else:
            feedback_parts.append(
                "ğŸ’ª ã‚„ã‚ŠæŠœãåŠ›ã‚’é›ãˆã‚‹ãŸã‚ã«ã€å°ã•ãªç›®æ¨™ã‹ã‚‰å§‹ã‚ã¦é”æˆæ„Ÿã‚’ç©ã¿é‡ã­ã¦ã„ãã¾ã—ã‚‡ã†ã€‚"
            )

        if skills.collaboration >= 4.0:
            feedback_parts.append(
                "ğŸ¤ å”èª¿æ€§ãŒã¨ã¦ã‚‚é«˜ã„ã§ã™ï¼ä»–è€…ã¨ã®å”åŠ›ã‚’å¤§åˆ‡ã«ã—ã¦ã„ã¾ã™ã­ã€‚"
            )
        elif skills.collaboration >= 3.0:
            feedback_parts.append(
                "ğŸ‘¥ å”èª¿æ€§ãŒè‚²ã£ã¦ã„ã¾ã™ã€‚ã‚°ãƒ«ãƒ¼ãƒ—å­¦ç¿’ã‚„ãƒšã‚¢å­¦ç¿’ã‚’æ´»ç”¨ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
            )
        else:
            feedback_parts.append(
                "ğŸ¤ å”èª¿æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€å‹é”ã¨ä¸€ç·’ã«å‹‰å¼·ã—ãŸã‚Šã€è³ªå•ã‚’ç©æ¥µçš„ã«ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
            )

        if skills.self_regulation >= 4.0:
            feedback_parts.append(
                "ğŸ¯ è‡ªå·±åˆ¶å¾¡åŠ›ãŒå„ªã‚Œã¦ã„ã¾ã™ï¼è¨ˆç”»çš„ã«å­¦ç¿’ã‚’é€²ã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚"
            )
        elif skills.self_regulation >= 3.0:
            feedback_parts.append(
                "ğŸ“ è‡ªå·±åˆ¶å¾¡åŠ›ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ã€‚å­¦ç¿’è¨ˆç”»ã‚’ç«‹ã¦ã¦å®Ÿè¡Œã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
            )
        else:
            feedback_parts.append(
                "â° è‡ªå·±åˆ¶å¾¡åŠ›ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€å­¦ç¿’æ™‚é–“ã‚’æ±ºã‚ã¦é›†ä¸­ã—ã¦å–ã‚Šçµ„ã‚“ã§ã¿ã¾ã—ã‚‡ã†ã€‚"
            )

        if skills.emotional_intelligence >= 4.0:
            feedback_parts.append(
                "ğŸ’ æ„Ÿæƒ…çŸ¥èƒ½ãŒé«˜ã„ã§ã™ï¼è‡ªåˆ†ã®æ„Ÿæƒ…ã‚’ç†è§£ã—ã€é©åˆ‡ã«è¡¨ç¾ã§ãã¦ã„ã¾ã™ã€‚"
            )
        elif skills.emotional_intelligence >= 3.0:
            feedback_parts.append(
                "ğŸ˜Š æ„Ÿæƒ…çŸ¥èƒ½ãŒè‚²ã£ã¦ã„ã¾ã™ã€‚æ„Ÿæƒ…ã‚’è¨€è‘‰ã§è¡¨ç¾ã™ã‚‹ç·´ç¿’ã‚’ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
            )
        else:
            feedback_parts.append(
                "ğŸ’­ æ„Ÿæƒ…çŸ¥èƒ½ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€è‡ªåˆ†ã®æ°—æŒã¡ã‚’æŒ¯ã‚Šè¿”ã‚‹æ™‚é–“ã‚’ä½œã£ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
            )

        # é€²æ­©ã®è©•ä¾¡
        if previous_skills:
            improvements = []
            if skills.grit > previous_skills.grit + 0.2:
                improvements.append("ã‚„ã‚ŠæŠœãåŠ›")
            if skills.collaboration > previous_skills.collaboration + 0.2:
                improvements.append("å”èª¿æ€§")
            if skills.self_regulation > previous_skills.self_regulation + 0.2:
                improvements.append("è‡ªå·±åˆ¶å¾¡åŠ›")
            if (
                skills.emotional_intelligence
                > previous_skills.emotional_intelligence + 0.2
            ):
                improvements.append("æ„Ÿæƒ…çŸ¥èƒ½")

            if improvements:
                feedback_parts.append(
                    f"ğŸ‰ ç´ æ™´ã‚‰ã—ã„é€²æ­©ã§ã™ï¼{', '.join(improvements)}ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ã€‚"
                )

        return "\n\n".join(feedback_parts)
